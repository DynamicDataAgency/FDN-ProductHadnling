{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query FTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### jupyter nbconvert --to script Continue-Update-Process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory:\n",
      "Fanatics-Product-Catalog_CUSTOM.txt.gz\n",
      "Fanatics-Product-Catalog_IR.txt.gz\n",
      "Fanatics-Top-Products_CUSTOM.txt.gz\n",
      "Fanatics-Top-Products_IR.txt.gz\n",
      "Fanatics-UK_CUSTOM.txt.gz\n",
      "Fanatics-UK_IR.txt.gz\n",
      "Fanatics-France_CUSTOM.txt.gz\n",
      "Fanatics-France_IR.txt.gz\n",
      "Fanatics-Spain_CUSTOM.txt.gz\n",
      "Fanatics-Spain_IR.txt.gz\n",
      "Fanatics-Germany_CUSTOM.txt.gz\n",
      "Fanatics-Germany_IR.txt.gz\n",
      "Fanatics-Australia_CUSTOM.txt.gz\n",
      "Fanatics-Australia_IR.txt.gz\n",
      "Fanatics-Italy_CUSTOM.txt.gz\n",
      "Fanatics-Italy_IR.txt.gz\n",
      "Downloaded Fanatics-Product-Catalog_IR.txt.gz to data-update-process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'221 Goodbye.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import time\n",
    "\n",
    "# FTP server details\n",
    "ftp_server = \"products.impact.com\"\n",
    "ftp_user = \"ps-ftp_5567077\"\n",
    "ftp_password = \"6r%]mobnH6\"\n",
    "ftp_directory = \"/Fanatics-(Global)/\"\n",
    "file_to_download = \"Fanatics-Product-Catalog_IR.txt.gz\"  # Specify the file to download\n",
    "\n",
    "# Local directory to save the file\n",
    "local_directory = \"data-update-process\"\n",
    "os.makedirs(local_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "max_retries = 3\n",
    "retry_delay = 5  # Delay in seconds between retries\n",
    "\n",
    "def download_file():\n",
    "    \"\"\"Attempt to connect to FTP and download the specified file.\"\"\"\n",
    "    try:\n",
    "        # Connect to the FTP server\n",
    "        ftp = ftplib.FTP(ftp_server)\n",
    "        ftp.set_debuglevel(2)  # Enable FTP command logging\n",
    "        ftp.set_pasv(True)  # Enable passive mode\n",
    "\n",
    "        ftp.login(user=ftp_user, passwd=ftp_password)\n",
    "        ftp.cwd(ftp_directory)\n",
    "\n",
    "        # List files in the directory\n",
    "        files = ftp.nlst()\n",
    "        print(\"Files in the directory:\")\n",
    "        for file in files:\n",
    "            print(file)\n",
    "\n",
    "        # Download only the specified file\n",
    "        if file_to_download in files:\n",
    "            local_filename = os.path.join(local_directory, file_to_download)  # Save in the folder\n",
    "            with open(local_filename, 'wb') as local_file:\n",
    "                ftp.retrbinary('RETR ' + file_to_download, local_file.write)\n",
    "                print(f\"Downloaded {file_to_download} to {local_directory}\")\n",
    "        else:\n",
    "            print(f\"{file_to_download} not found in the directory.\")\n",
    "        \n",
    "        ftp.quit()  # Ensure connection is closed\n",
    "\n",
    "    except ftplib.all_errors as e:\n",
    "        print(f\"FTP error: {e}\")\n",
    "        raise  # Raise the error to be handled by the retry mechanism\n",
    "\n",
    "\n",
    "# Retry mechanism\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        download_file()  # Call the function to perform the FTP download\n",
    "        break  # If the download succeeds, exit the retry loop\n",
    "    except (ftplib.error_temp, ConnectionResetError) as e:\n",
    "        print(f\"Temporary error occurred: {e}. Retrying ({attempt + 1}/{max_retries})...\")\n",
    "        if attempt == max_retries - 1:\n",
    "            print(\"Max retries reached. Exiting.\")\n",
    "            raise e  # Re-raise the exception if all retries fail\n",
    "        time.sleep(retry_delay)  # Wait before retrying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompress downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompressed c:\\Dynamic data\\FDN\\FDN-ProductHadnling\\data-update-process\\Fanatics-Product-Catalog_IR.txt.gz to c:\\Dynamic data\\FDN\\FDN-ProductHadnling\\data-update-process\\Fanatics-Product-Catalog_IR.txt\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Directory containing the downloaded .txt.gz files\n",
    "directory = os.path.join(os.getcwd(), \"data-update-process\")  # Path to the downloaded files\n",
    "\n",
    "# Decompress each .txt.gz file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt.gz'):\n",
    "        local_gz_filename = os.path.join(directory, filename)\n",
    "        local_txt_filename = os.path.join(directory, filename[:-3])  # Remove the .gz extension\n",
    "\n",
    "        # Decompress the .txt.gz file to .txt\n",
    "        with gzip.open(local_gz_filename, 'rb') as f_in:\n",
    "            with open(local_txt_filename, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "                print(f\"Decompressed {local_gz_filename} to {local_txt_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_22360\\4281405362.py:13: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(local_txt_filename, delimiter='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique Merchant SKU                                       Product Name  \\\n",
      "0              3180765  Men's New Era Black Minnesota Vikings Black On...   \n",
      "1              5257010  Men's Under Armour Gray Virginia Tech Hokies S...   \n",
      "2            200180351  Women's Antigua  Navy Jacksonville Jumbo Shrim...   \n",
      "3            200465364   Keyscaper  Rey Mysterio Galaxy Impact Clear Case   \n",
      "4            201060326  Women's Cutter & Buck  Gray Los Angeles Dodger...   \n",
      "\n",
      "                                         Product URL  \\\n",
      "0  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "1  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "2  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "3  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "4  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "\n",
      "                                           Image URL  Current Price  \\\n",
      "0  https://feeds.frgimages.com/_pi3180000_ff_3180...          34.99   \n",
      "1  https://feeds.frgimages.com/_pi5257000_ff_5257...          39.99   \n",
      "2  https://feeds.frgimages.com/_ss5_p-200180351+u...          74.99   \n",
      "3  https://feeds.frgimages.com/_ss5_p-200465364+u...          34.99   \n",
      "4  https://feeds.frgimages.com/_ss5_p-201060326+u...         234.99   \n",
      "\n",
      "  Stock Availability Condition  EAN  \\\n",
      "0                  Y       New  NaN   \n",
      "1                  Y       New  NaN   \n",
      "2                  Y       New  NaN   \n",
      "3                  Y       New  NaN   \n",
      "4                  Y       New  NaN   \n",
      "\n",
      "                                                 UPC ISBN  ...  Numeric1  \\\n",
      "0                                       192859235471  NaN  ...       NaN   \n",
      "1  197141891441;197141891434;197141891427;1971418...  NaN  ...       NaN   \n",
      "2  197719364094;197719364100;197719364117;1977193...  NaN  ...       NaN   \n",
      "3  197281171847;197281173643;197281172028;1972819...  NaN  ...       NaN   \n",
      "4  197948909677;197948909646;197948909639;1979489...  NaN  ...       NaN   \n",
      "\n",
      "   Numeric2  Numeric3  Money1  Money2 Money3 Currency  Shipping Region Labels  \\\n",
      "0      0.41       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "1      0.41       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "2      0.41       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "3      0.50       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "4      0.40       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "\n",
      "   Promotion  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "directory = os.path.join(os.getcwd(), \"data-update-process\")\n",
    "\n",
    "# Path to the decompressed .txt file\n",
    "local_txt_filename = os.path.join(directory, \"Fanatics-Product-Catalog_IR.txt\")\n",
    "\n",
    "# Load the decompressed .txt file into a Pandas DataFrame\n",
    "if os.path.exists(local_txt_filename):\n",
    "    # Assuming the file is tab-delimited, adjust the delimiter if necessary\n",
    "    df = pd.read_csv(local_txt_filename, delimiter='\\t', low_memory=False)\n",
    "    print(df.head())  # Display the first 5 rows\n",
    "else:\n",
    "    print(f\"{local_txt_filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter needed products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df[\"Category\"] == \"NFL\"]\n",
    "df=df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 70)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations to fit Shopify product import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the occurrences of each value in the 'Text3' column of the 'nf' dataframe\n",
    "# text3_counts = nf['Text3'].value_counts()\n",
    "\n",
    "# Print the top 60 values\n",
    "#  print(text3_counts.head(60))\n",
    "\n",
    "nf = df.loc[:, ['Unique Merchant SKU', 'Product Name', 'Product URL', 'Image URL', 'Current Price', 'Original Price', 'Product Description', 'Gender', 'Text1', 'Text2', 'Text3','Size']]\n",
    "\n",
    "rename_dict = {\n",
    "    'Unique Merchant SKU': 'ID',\n",
    "    'Product Name': 'Title',\n",
    "    'Product URL': 'Metafield: custom.product_url [url]',\n",
    "    'Image URL': 'Image Src',\n",
    "    'Current Price': 'Variant Price',\n",
    "    'Original Price': 'Variant Compare At Price',\n",
    "    'Product Description': 'Body HTML',\n",
    "    'Gender': 'Metafield: custom.product_gender [single_line_text_field]',\n",
    "    'Text1': 'Metafield: custom.text1 [single_line_text_field]',\n",
    "    'Text2': 'Metafield: custom.text2 [single_line_text_field]',\n",
    "    'Text3': 'Tags',\n",
    "    'Size': 'Metafield: custom.sizes [single_line_text_field]'\n",
    "}\n",
    "\n",
    "nf = nf.rename(columns=rename_dict)\n",
    "\n",
    "\n",
    "\n",
    "## remove emptyspaces in Tags column between values\n",
    "nf['Tags'] = nf['Tags'].str.replace(' ', '')\n",
    "\n",
    "# Create an additional column 'Variant Inventory Tracker' with all values value 'shopify'\n",
    "nf['Variant Inventory Tracker'] = 'shopify'\n",
    "nf['Variant Inventory Policy'] = 'continue'\n",
    "nf['Variant Fulfillment Service'] = 'manual'\n",
    "nf['Variant Inventory Qty'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#./myenv/Scripts/Activate.ps1\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "# Define the scope\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Add credentials to the account\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(process.env.CREDENTIALS_GOOGLE_CLOUD, scope)\n",
    "\n",
    "# Authorize the clientsheet\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet (by name or by key)\n",
    "spreadsheet = client.open(\"Fanatics_product_import\")\n",
    "\n",
    "# Select the first sheet (or specify another sheet)\n",
    "sheet = spreadsheet.sheet1  \n",
    "\n",
    "\n",
    "# Clear existing data in the sheet (optional)\n",
    "sheet.clear()\n",
    "\n",
    "# Write DataFrame to Google Sheet\n",
    "set_with_dataframe(sheet, nf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

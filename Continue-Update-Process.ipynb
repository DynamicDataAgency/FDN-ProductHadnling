{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query FTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### jupyter nbconvert --to script Continue-Update-Process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*cmd* 'USER ps-ftp_5567077'\n",
      "*put* 'USER ps-ftp_5567077\\r\\n'\n",
      "*get* '331 User name okay, need password for ps-ftp_5567077.\\n'\n",
      "*resp* '331 User name okay, need password for ps-ftp_5567077.'\n",
      "*cmd* 'PASS **********'\n",
      "*put* 'PASS **********\\r\\n'\n",
      "*get* '230 User logged in, proceed.\\n'\n",
      "*resp* '230 User logged in, proceed.'\n",
      "*cmd* 'CWD /Fanatics-(Global)/'\n",
      "*put* 'CWD /Fanatics-(Global)/\\r\\n'\n",
      "*get* '250 Directory changed to /Fanatics-(Global)/\\n'\n",
      "*resp* '250 Directory changed to /Fanatics-(Global)/'\n",
      "*cmd* 'TYPE A'\n",
      "*put* 'TYPE A\\r\\n'\n",
      "*get* '200 Command TYPE okay.\\n'\n",
      "*resp* '200 Command TYPE okay.'\n",
      "*cmd* 'PASV'\n",
      "*put* 'PASV\\r\\n'\n",
      "*get* '227 Entering Passive Mode (35,207,5,176,169,191)\\n'\n",
      "*resp* '227 Entering Passive Mode (35,207,5,176,169,191)'\n",
      "*cmd* 'NLST'\n",
      "*put* 'NLST\\r\\n'\n",
      "*get* '150 File status okay; about to open data connection.\\n'\n",
      "*resp* '150 File status okay; about to open data connection.'\n",
      "*get* '226 Closing data connection.\\n'\n",
      "*resp* '226 Closing data connection.'\n",
      "Files in the directory:\n",
      "Fanatics-Product-Catalog_CUSTOM.txt.gz\n",
      "Fanatics-Product-Catalog_IR.txt.gz\n",
      "Fanatics-Top-Products_CUSTOM.txt.gz\n",
      "Fanatics-Top-Products_IR.txt.gz\n",
      "Fanatics-UK_CUSTOM.txt.gz\n",
      "Fanatics-UK_IR.txt.gz\n",
      "Fanatics-France_CUSTOM.txt.gz\n",
      "Fanatics-France_IR.txt.gz\n",
      "Fanatics-Spain_CUSTOM.txt.gz\n",
      "Fanatics-Spain_IR.txt.gz\n",
      "Fanatics-Germany_CUSTOM.txt.gz\n",
      "Fanatics-Germany_IR.txt.gz\n",
      "Fanatics-Australia_CUSTOM.txt.gz\n",
      "Fanatics-Australia_IR.txt.gz\n",
      "Fanatics-Italy_CUSTOM.txt.gz\n",
      "Fanatics-Italy_IR.txt.gz\n",
      "*cmd* 'TYPE I'\n",
      "*put* 'TYPE I\\r\\n'\n",
      "*get* '200 Command TYPE okay.\\n'\n",
      "*resp* '200 Command TYPE okay.'\n",
      "*cmd* 'PASV'\n",
      "*put* 'PASV\\r\\n'\n",
      "*get* '227 Entering Passive Mode (35,207,5,176,216,24)\\n'\n",
      "*resp* '227 Entering Passive Mode (35,207,5,176,216,24)'\n",
      "*cmd* 'RETR Fanatics-Product-Catalog_IR.txt.gz'\n",
      "*put* 'RETR Fanatics-Product-Catalog_IR.txt.gz\\r\\n'\n",
      "*get* '150 File status okay; about to open data connection.\\n'\n",
      "*resp* '150 File status okay; about to open data connection.'\n",
      "*get* '226 Transfer complete.\\n'\n",
      "*resp* '226 Transfer complete.'\n",
      "Downloaded Fanatics-Product-Catalog_IR.txt.gz to data-update-process\n",
      "*cmd* 'QUIT'\n",
      "*put* 'QUIT\\r\\n'\n",
      "*get* '221 Goodbye.\\n'\n",
      "*resp* '221 Goodbye.'\n"
     ]
    }
   ],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import time\n",
    "\n",
    "# FTP server details\n",
    "ftp_server = \"products.impact.com\"\n",
    "ftp_user = \"ps-ftp_5567077\"\n",
    "ftp_password = \"6r%]mobnH6\"\n",
    "ftp_directory = \"/Fanatics-(Global)/\"\n",
    "file_to_download = \"Fanatics-Product-Catalog_IR.txt.gz\"  # Specify the file to download\n",
    "\n",
    "# Local directory to save the file\n",
    "local_directory = \"data-update-process\"\n",
    "os.makedirs(local_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "max_retries = 3\n",
    "retry_delay = 5  # Delay in seconds between retries\n",
    "\n",
    "def download_file():\n",
    "    \"\"\"Attempt to connect to FTP and download the specified file.\"\"\"\n",
    "    try:\n",
    "        # Connect to the FTP server\n",
    "        ftp = ftplib.FTP(ftp_server)\n",
    "        ftp.set_debuglevel(2)  # Enable FTP command logging\n",
    "        ftp.set_pasv(True)  # Enable passive mode\n",
    "\n",
    "        ftp.login(user=ftp_user, passwd=ftp_password)\n",
    "        ftp.cwd(ftp_directory)\n",
    "\n",
    "        # List files in the directory\n",
    "        files = ftp.nlst()\n",
    "        print(\"Files in the directory:\")\n",
    "        for file in files:\n",
    "            print(file)\n",
    "\n",
    "        # Download only the specified file\n",
    "        if file_to_download in files:\n",
    "            local_filename = os.path.join(local_directory, file_to_download)  # Save in the folder\n",
    "            with open(local_filename, 'wb') as local_file:\n",
    "                ftp.retrbinary('RETR ' + file_to_download, local_file.write)\n",
    "                print(f\"Downloaded {file_to_download} to {local_directory}\")\n",
    "        else:\n",
    "            print(f\"{file_to_download} not found in the directory.\")\n",
    "        \n",
    "        ftp.quit()  # Ensure connection is closed\n",
    "\n",
    "    except ftplib.all_errors as e:\n",
    "        print(f\"FTP error: {e}\")\n",
    "        raise  # Raise the error to be handled by the retry mechanism\n",
    "\n",
    "\n",
    "# Retry mechanism\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        download_file()  # Call the function to perform the FTP download\n",
    "        break  # If the download succeeds, exit the retry loop\n",
    "    except (ftplib.error_temp, ConnectionResetError) as e:\n",
    "        print(f\"Temporary error occurred: {e}. Retrying ({attempt + 1}/{max_retries})...\")\n",
    "        if attempt == max_retries - 1:\n",
    "            print(\"Max retries reached. Exiting.\")\n",
    "            raise e  # Re-raise the exception if all retries fail\n",
    "        time.sleep(retry_delay)  # Wait before retrying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompress downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompressed c:\\Dynamic data\\FDN\\FDN-ProductHadnling\\data-update-process\\Fanatics-Product-Catalog_IR.txt.gz to c:\\Dynamic data\\FDN\\FDN-ProductHadnling\\data-update-process\\Fanatics-Product-Catalog_IR.txt\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Directory containing the downloaded .txt.gz files\n",
    "directory = os.path.join(os.getcwd(), \"data-update-process\")  # Path to the downloaded files\n",
    "\n",
    "# Decompress each .txt.gz file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt.gz'):\n",
    "        local_gz_filename = os.path.join(directory, filename)\n",
    "        local_txt_filename = os.path.join(directory, filename[:-3])  # Remove the .gz extension\n",
    "\n",
    "        # Decompress the .txt.gz file to .txt\n",
    "        with gzip.open(local_gz_filename, 'rb') as f_in:\n",
    "            with open(local_txt_filename, 'wb') as f_out: \n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "                print(f\"Decompressed {local_gz_filename} to {local_txt_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique Merchant SKU                                       Product Name  \\\n",
      "0      200341170336101  Riccardo Calafiori Women's adidas  Yellow Arse...   \n",
      "1              3180765  Men's New Era Black Minnesota Vikings Black On...   \n",
      "2              5257010  Men's Under Armour Gray Virginia Tech Hokies S...   \n",
      "3            200180351  Women's Antigua  Navy Jacksonville Jumbo Shrim...   \n",
      "4            200465364   Keyscaper  Rey Mysterio Galaxy Impact Clear Case   \n",
      "\n",
      "                                         Product URL  \\\n",
      "0  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "1  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "2  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "3  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "4  https://fanatics.93n6tx.net/c/5567077/669352/9...   \n",
      "\n",
      "                                           Image URL  Current Price  \\\n",
      "0  https://feeds.frgimages.com/lf?set=key[name],v...          94.49   \n",
      "1  https://feeds.frgimages.com/_pi3180000_ff_3180...          26.24   \n",
      "2  https://feeds.frgimages.com/_pi5257000_ff_5257...          39.99   \n",
      "3  https://feeds.frgimages.com/_ss5_p-200180351+u...          52.49   \n",
      "4  https://feeds.frgimages.com/_ss5_p-200465364+u...          26.24   \n",
      "\n",
      "  Stock Availability Condition  EAN  \\\n",
      "0                  Y       New  NaN   \n",
      "1                  Y       New  NaN   \n",
      "2                  Y       New  NaN   \n",
      "3                  Y       New  NaN   \n",
      "4                  Y       New  NaN   \n",
      "\n",
      "                                                 UPC ISBN  ...  Numeric1  \\\n",
      "0                                                  ;  NaN  ...       NaN   \n",
      "1                                       192859235471  NaN  ...       NaN   \n",
      "2  197141891441;197141891397;197141891427;1971418...  NaN  ...       NaN   \n",
      "3  197719364131;197719364094;197719364124;1977193...  NaN  ...       NaN   \n",
      "4  197281171489;197281172028;197281171847;1972819...  NaN  ...       NaN   \n",
      "\n",
      "   Numeric2  Numeric3  Money1  Money2 Money3 Currency  Shipping Region Labels  \\\n",
      "0      0.44       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "1      0.41       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "2      0.41       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "3      0.41       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "4      0.50       NaN     NaN     NaN    NaN      USD              NaN    NaN   \n",
      "\n",
      "   Promotion  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "directory = os.path.join(os.getcwd(), \"data-update-process\")\n",
    "\n",
    "# Path to the decompressed .txt file\n",
    "local_txt_filename = os.path.join(directory, \"Fanatics-Product-Catalog_IR.txt\")\n",
    "\n",
    "# Load the decompressed .txt file into a Pandas DataFrame\n",
    "if os.path.exists(local_txt_filename):\n",
    "    # Assuming the file is tab-delimited, adjust the delimiter if necessary\n",
    "    df = pd.read_csv(local_txt_filename, delimiter='\\t', low_memory=False)\n",
    "    print(df.head())  # Display the first 5 rows\n",
    "else:\n",
    "    print(f\"{local_txt_filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter needed products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df[\"Category\"] == \"NFL\"]\n",
    "df=df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 70)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations to fit Shopify product import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the occurrences of each value in the 'Text3' column of the 'nf' dataframe\n",
    "# text3_counts = nf['Text3'].value_counts()\n",
    "\n",
    "# Print the top 60 values\n",
    "#  print(text3_counts.head(60))\n",
    "\n",
    "nf = df.loc[:, ['Unique Merchant SKU', 'Product Name', 'Product URL', 'Image URL', 'Current Price', 'Original Price', 'Product Description', 'Gender', 'Text1', 'Text2', 'Text3','Size']]\n",
    "\n",
    "rename_dict = {\n",
    "    'Unique Merchant SKU': 'ID',\n",
    "    'Product Name': 'Title',\n",
    "    'Product URL': 'Metafield: custom.product_url [url]',\n",
    "    'Image URL': 'Image Src',\n",
    "    'Current Price': 'Variant Price',\n",
    "    'Original Price': 'Variant Compare At Price',\n",
    "    'Product Description': 'Body HTML',\n",
    "    'Gender': 'Metafield: custom.product_gender [single_line_text_field]',\n",
    "    'Text1': 'Metafield: custom.text1 [single_line_text_field]',\n",
    "    'Text2': 'Metafield: custom.text2 [single_line_text_field]',\n",
    "    'Text3': 'Tags',\n",
    "    'Size': 'Metafield: custom.sizes [single_line_text_field]'\n",
    "}\n",
    "\n",
    "nf = nf.rename(columns=rename_dict)\n",
    "\n",
    "\n",
    "\n",
    "## remove emptyspaces in Tags column between values\n",
    "nf['Tags'] = nf['Tags'].str.replace(' ', '')\n",
    "\n",
    "# Create an additional column 'Variant Inventory Tracker' with all values value 'shopify'\n",
    "nf['Variant Inventory Tracker'] = 'shopify'\n",
    "nf['Variant Inventory Policy'] = 'continue'\n",
    "nf['Variant Fulfillment Service'] = 'manual'\n",
    "nf['Variant Inventory Qty'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedSubstrateError",
     "evalue": "Cannot convert str to a seekable bit stream.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Dynamic data\\FDN\\FDN-ProductHadnling\\.venv\\Lib\\site-packages\\pyasn1\\codec\\streaming.py:107\u001b[0m, in \u001b[0;36masSeekableStream\u001b[1;34m(substrate)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msubstrate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseekable\u001b[49m():  \u001b[38;5;66;03m# Will fail for most invalid types\u001b[39;00m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m substrate\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'seekable'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnsupportedSubstrateError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(CredentialsJson, json_file)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Authorize using the JSON file directly\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m creds \u001b[38;5;241m=\u001b[39m \u001b[43mServiceAccountCredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json_keyfile_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcredentials.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Authorize the clientsheet\u001b[39;00m\n\u001b[0;32m     38\u001b[0m client \u001b[38;5;241m=\u001b[39m gspread\u001b[38;5;241m.\u001b[39mauthorize(creds)\n",
      "File \u001b[1;32mc:\\Dynamic data\\FDN\\FDN-ProductHadnling\\.venv\\Lib\\site-packages\\oauth2client\\service_account.py:221\u001b[0m, in \u001b[0;36mServiceAccountCredentials.from_json_keyfile_name\u001b[1;34m(cls, filename, scopes, token_uri, revoke_uri)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[0;32m    220\u001b[0m     client_credentials \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file_obj)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parsed_json_keyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_credentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtoken_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mrevoke_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevoke_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Dynamic data\\FDN\\FDN-ProductHadnling\\.venv\\Lib\\site-packages\\oauth2client\\service_account.py:185\u001b[0m, in \u001b[0;36mServiceAccountCredentials._from_parsed_json_keyfile\u001b[1;34m(cls, keyfile_dict, scopes, token_uri, revoke_uri)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m revoke_uri:\n\u001b[0;32m    182\u001b[0m     revoke_uri \u001b[38;5;241m=\u001b[39m keyfile_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevoke_uri\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    183\u001b[0m                                   oauth2client\u001b[38;5;241m.\u001b[39mGOOGLE_REVOKE_URI)\n\u001b[1;32m--> 185\u001b[0m signer \u001b[38;5;241m=\u001b[39m \u001b[43mcrypt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSigner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprivate_key_pkcs8_pem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(service_account_email, signer, scopes\u001b[38;5;241m=\u001b[39mscopes,\n\u001b[0;32m    187\u001b[0m                   private_key_id\u001b[38;5;241m=\u001b[39mprivate_key_id,\n\u001b[0;32m    188\u001b[0m                   client_id\u001b[38;5;241m=\u001b[39mclient_id, token_uri\u001b[38;5;241m=\u001b[39mtoken_uri,\n\u001b[0;32m    189\u001b[0m                   revoke_uri\u001b[38;5;241m=\u001b[39mrevoke_uri)\n\u001b[0;32m    190\u001b[0m credentials\u001b[38;5;241m.\u001b[39m_private_key_pkcs8_pem \u001b[38;5;241m=\u001b[39m private_key_pkcs8_pem\n",
      "File \u001b[1;32mc:\\Dynamic data\\FDN\\FDN-ProductHadnling\\.venv\\Lib\\site-packages\\oauth2client\\_pure_python_crypt.py:174\u001b[0m, in \u001b[0;36mRsaSigner.from_string\u001b[1;34m(cls, key, password)\u001b[0m\n\u001b[0;32m    171\u001b[0m     pkey \u001b[38;5;241m=\u001b[39m rsa\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;241m.\u001b[39mPrivateKey\u001b[38;5;241m.\u001b[39mload_pkcs1(key_bytes,\n\u001b[0;32m    172\u001b[0m                                          \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDER\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m marker_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 174\u001b[0m     key_info, remaining \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masn1Spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_PKCS8_SPEC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnused bytes\u001b[39m\u001b[38;5;124m'\u001b[39m, remaining)\n",
      "File \u001b[1;32mc:\\Dynamic data\\FDN\\FDN-ProductHadnling\\.venv\\Lib\\site-packages\\pyasn1\\codec\\ber\\decoder.py:2076\u001b[0m, in \u001b[0;36mDecoder.__call__\u001b[1;34m(cls, substrate, asn1Spec, **options)\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1997\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, substrate, asn1Spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Turns BER/CER/DER octet stream into an ASN.1 object.\u001b[39;00m\n\u001b[0;32m   1999\u001b[0m \n\u001b[0;32m   2000\u001b[0m \u001b[38;5;124;03m    Takes BER/CER/DER octet-stream in form of :py:class:`bytes`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \n\u001b[0;32m   2075\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2076\u001b[0m     substrate \u001b[38;5;241m=\u001b[39m \u001b[43masSeekableStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstrate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2078\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstrateFun\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m options:\n\u001b[0;32m   2079\u001b[0m         origSubstrateFun \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubstrateFun\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Dynamic data\\FDN\\FDN-ProductHadnling\\.venv\\Lib\\site-packages\\pyasn1\\codec\\streaming.py:113\u001b[0m, in \u001b[0;36masSeekableStream\u001b[1;34m(substrate)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m CachingStreamWrapper(substrate)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mUnsupportedSubstrateError(\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m substrate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to a seekable bit stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mUnsupportedSubstrateError\u001b[0m: Cannot convert str to a seekable bit stream."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define the scope\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Save the credentials to a JSON file if not already saved\n",
    "CredentialsJson = {\n",
    "    \"type\": os.getenv(\"TYPE\"),\n",
    "    \"project_id\": os.getenv(\"PROJECT_ID\"),\n",
    "    \"private_key_id\": os.getenv(\"PRIVATE_KEY_ID\"),\n",
    "    \"private_key\": os.getenv(\"PRIVATE_KEY\"),\n",
    "    \"client_email\": os.getenv(\"CLIENT_EMAIL\"),\n",
    "    \"client_id\": os.getenv(\"CLIENT_ID\"),\n",
    "    \"auth_uri\": os.getenv(\"AUTH_URI\"),\n",
    "    \"token_uri\": os.getenv(\"TOKEN_URI\"),\n",
    "    \"auth_provider_x509_cert_url\": os.getenv(\"AUTH_PROVIDER_X509_CERT_URL\"),\n",
    "    \"client_x509_cert_url\": os.getenv(\"CLIENT_X509_CERT_URL\"),\n",
    "    \"universe_domain\": os.getenv(\"UNIVERSE_DOMAIN\")\n",
    "}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open('credentials.json', 'w') as json_file:\n",
    "    json.dump(CredentialsJson, json_file)\n",
    "\n",
    "# Authorize using the JSON file directly\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)\n",
    "\n",
    "# Authorize the clientsheet\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet (by name or by key)\n",
    "spreadsheet = client.open(\"Fanatics_product_import\")\n",
    "\n",
    "# Select the first sheet (or specify another sheet)\n",
    "sheet = spreadsheet.sheet1  \n",
    "\n",
    "# Clear existing data in the sheet (optional)\n",
    "sheet.clear()\n",
    "\n",
    "# Write DataFrame to Google Sheet (ensure 'nf' is a valid DataFrame)\n",
    "set_with_dataframe(sheet, nf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "import json  \n",
    "\n",
    "\n",
    "CredentialsJson = {\n",
    "  \"type\": os.getenv(\"TYPE\"),\n",
    "  \"project_id\": os.getenv(\"PROJECT_ID\"),\n",
    "  \"private_key_id\": os.getenv(\"PRIVATE_KEY_ID\"),\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDgi/ULG3fwgxbi\\npsWUpCwOkEjwAc7aSG4A2eCUTiC8nPEzM628EgjgQXN3Ef9rTqHQ8JNgUTDlzKqo\\nnpQ+8JBYeH2s7YVG3IuytakS81vofjAGyTPRk7Cf3ih8TGicjam7kCDdL9FyFPIx\\nQpABIKnWbdv4tV/Y/lIrvyCZ9+VH6B0SSK48yIh0nHvyq3EoUQZmbawiWf0m/FPS\\n6lrX98xiyMpA9gYQ5eV8JH6iLBQgv8I1tAmheE64B/SufHgTQWAbJO9/uVOxo0Eh\\nnfAt602BMyxCAVec1Ctoc6nXJFMwzTef/ppCC8c2jkIXE70zSPYffXtoCiBCfRP5\\nZA7sO/jTAgMBAAECggEAGbNLJ6tMLgYC/4wQ/zNPK5eOEZJTZ550oLpPPwo2KwBX\\nhwG6N9VkmK5FFfLEZjbIxI5Uf+irDRJA0i3cT9ve2ZFo6PsCjxq9DoZGRLn/4ftX\\nad9rg+hAhfu6bIeeTZTVQXd8m3RWp5UIJ2Uz8D0Z00YdsDiqML7jDsjAZX7/Chyr\\nGoY9Jo1aHq0VostiyAYPTYMhEMH+/OdeKVD+JysNSwrR7lEKCAPlrKAa58iRVawc\\n8MMdhS+WjOit9Zx//X/ZgBvA3eubrwrxkFq8Uxsh5VtBnHk+6waidW5nW8Mlc8o3\\nt6JrpPImwKtNbZcfrrBuGWJ+S4FJXshNUMeGb9aZGQKBgQD0QF+AmABEWxi9uDZv\\n6SuxQS9UwCPtmvqZk+OorIFEOUApWRaMPMmpgy2xq8oVxyFRO/0z7JqQg1Pnqlyh\\nriHzBk862H6SbxKhSCmWnJiAwEcFjvEFHHubf5ONIsiLE4rPfqJmMjjBtnFb9sOS\\nNv2BSQtp+8y+OJB4x2L73C7gFQKBgQDrWPJeul5gJw6IwK9Psdur6ltMBcnQGtuR\\nvwD6/r9QFd8lWtqVZxr7asqEegkVg+xe23lksiHWwvp2iEoaPjiucH78O4C7gRFE\\n65EQKXzy5JT0BwaDkbuWW5ZDvf/vDrKa2cmTnCJ7zANvf4w5qtNUjuQ0pM4yFeFo\\nnRsSvj5HRwKBgQCu/nft//khAEtnkdWetGYTZupsRAT5tTGaWrSfIoiywnnPpf5b\\nlym8gzl3s+bjV3ntY5dzXi8XHqA8uHgJdmLoZTrapEV60I1+c98oAyXYCOpZdyID\\nUXbV379tPOCFlAi9xLLBmXXEg9wP0WopFbDmsdi1pCv6lTgc8G1gmU4USQKBgBy5\\nk4OKXcCAo95/Hias/7Hg/dmujy5OSORmGrmH5FPjB4RorWs01W9AXo2C058DphMB\\n2LQ4pbavv6A+DEVduM9ZvbYNkS3RmAkAc4k0dyKyUZfjT6E5ZVr5vMJx604DTjtm\\nP5s7oF3ZzcWLHNNhDUAx3JqsTtqAHy4EluxXugQ7AoGAUQe4xZjlRcsWLCgAc1UP\\nfc8YsE0ctVpsYPb9c/Yzh7uVnrCHQ1QVD4aSf6TjGtRMnVgQXlR40y4S7Tg727x9\\nlv+jYmK7RLKvWxgi5AIWQnz8QqWso/XsmFCmG+2XvLJ/jW+Vfcu27D0ROlQb4RKI\\nV6YQkl6+DGwtHVECtRA68Bo=\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": os.getenv(\"CLIENT_EMAIL\"),\n",
    "  \"client_id\": os.getenv(\"CLIENT_ID\"),\n",
    "  \"auth_uri\": os.getenv(\"AUTH_URI\"),\n",
    "  \"token_uri\": os.getenv(\"TOKEN_URI\"),\n",
    "  \"auth_provider_x509_cert_url\": os.getenv(\"AUTH_PROVIDER_X509_CERT_URL\"),\n",
    "  \"client_x509_cert_url\": os.getenv(\"CLIENT_X509_CERT_URL\"),\n",
    "  \"universe_domain\": os.getenv(\"UNIVERSE_DOMAIN\")\n",
    "}\n",
    "\n",
    "with open('credentials.json', 'w') as json_file:\n",
    "    json.dump(CredentialsJson, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'service_account', 'project_id': 'temporal-frame-436108-u7', 'private_key_id': '3460803daf7a03dc3ac50631328e6a341f34062d', 'private_key': '-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDgi/ULG3fwgxbi\\npsWUpCwOkEjwAc7aSG4A2eCUTiC8nPEzM628EgjgQXN3Ef9rTqHQ8JNgUTDlzKqo\\nnpQ+8JBYeH2s7YVG3IuytakS81vofjAGyTPRk7Cf3ih8TGicjam7kCDdL9FyFPIx\\nQpABIKnWbdv4tV/Y/lIrvyCZ9+VH6B0SSK48yIh0nHvyq3EoUQZmbawiWf0m/FPS\\n6lrX98xiyMpA9gYQ5eV8JH6iLBQgv8I1tAmheE64B/SufHgTQWAbJO9/uVOxo0Eh\\nnfAt602BMyxCAVec1Ctoc6nXJFMwzTef/ppCC8c2jkIXE70zSPYffXtoCiBCfRP5\\nZA7sO/jTAgMBAAECggEAGbNLJ6tMLgYC/4wQ/zNPK5eOEZJTZ550oLpPPwo2KwBX\\nhwG6N9VkmK5FFfLEZjbIxI5Uf+irDRJA0i3cT9ve2ZFo6PsCjxq9DoZGRLn/4ftX\\nad9rg+hAhfu6bIeeTZTVQXd8m3RWp5UIJ2Uz8D0Z00YdsDiqML7jDsjAZX7/Chyr\\nGoY9Jo1aHq0VostiyAYPTYMhEMH+/OdeKVD+JysNSwrR7lEKCAPlrKAa58iRVawc\\n8MMdhS+WjOit9Zx//X/ZgBvA3eubrwrxkFq8Uxsh5VtBnHk+6waidW5nW8Mlc8o3\\nt6JrpPImwKtNbZcfrrBuGWJ+S4FJXshNUMeGb9aZGQ', 'client_email': 'spreadsheet@temporal-frame-436108-u7.iam.gserviceaccount.com', 'client_id': '117360647799956951283', 'auth_uri': 'https://accounts.google.com/o/oauth2/auth', 'token_uri': 'https://oauth2.googleapis.com/token', 'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs', 'client_x509_cert_url': 'https://www.googleapis.com/robot/v1/metadata/x509/spreadsheet%40temporal-frame-436108-u7.iam.gserviceaccount.com', 'universe_domain': 'googleapis.com'}\n"
     ]
    }
   ],
   "source": [
    "print( CredentialsJson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
